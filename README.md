#  Sign to Speak - Real-Time Sign Language Translator

##  Problem Statement
Millions of specially-abled people use sign language to communicate, but most people around them do not understand it. This creates a major barrier in daily interactions.

##  Objective
This project detects and translates **sign language gestures (A–Z, 0–9)** into **real-time text and speech**, bridging the communication gap between specially-abled and non-signing individuals.

---

## ⚙️ Tech Stack
- **Python**
- **OpenCV** – for webcam video input
- **MediaPipe** – for hand detection and tracking
- **Scikit-Learn** – for training a classification model
- **pyttsx3 / gTTS** – for text-to-speech output
- **Streamlit** (optional) – for deployment interface

**This Model Achieves 96.25% Accuracy**

## DataSet Link
Kaggle dataset in form of images of sign languages. Link 
ASL_Alphabets :- https://www.kaggle.com/datasets/debashishsau/aslamerican-sign-language-aplhabet-dataset
ASL_Digits :- https://www.kaggle.com/datasets/victoranthony/asl-digits-0-9

## Project Demo Video
Link :- https://drive.google.com/file/d/1P873hz-2RJEWNVsXUnrvsMwyM6LBjNPo/view?usp=drive_link

## Future Scope
**Reverse mode:** Convert text/speech into sign animations

**Add full-word gestures like "Hello", "Thanks"**

**Deploy as a mobile app or website**

**Add video call feature with live translation**

---
